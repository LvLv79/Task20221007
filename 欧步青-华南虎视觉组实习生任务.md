
# 华南虎视觉组实习生任务

实习生姓名：欧步青
## 一、kalman_Fan
---
### 1.功能介绍
本套代码用于识别大能量机关的中心点R以及流动条对应的装甲板
并在中心R点处标出当前能量机关的神符扇叶中心点和神符中心的连线与水平方向的角度，在装甲板中心点标出神符击打中心和相机的距离

---
### 2.整体框架
本套代码分为三大部分
第一部分：中心点R识别（class Filter）
第二部分：装甲板识别(class Flow)
第三部分：装甲板坐标标定（class sort）
第四部分：卡尔曼滤波（class kalman）
第五部分：重力补偿（class compensator）
第六部分：信息匹配(class target)

---
### 3.实现方案  
一、**中心点R识别（class Filter）**
通过通道相减法获得蓝色发光区域轮廓
并通过以下判断原理得到中心r型图形
筛选条件如下：
①r型图形没有子轮廓，没有父轮廓，且至少有一个同级轮廓。
②面积范围与最小外接矩形的长宽比

二、**装甲板识别(class Flow)**
与r型图形处理方法相似
筛选条件如下：
①装甲板没有子轮廓和同级轮廓，一定有父轮廓。
②面积范围与最小外接矩形的长宽比。

三、**装甲板坐标标定（class sort）**
找出左下（bl）和右下（br）两个点
1.先算出该点与中心R的距离，bl和br两个点一定为距离最小
2.再算出两点和中心点的向量AR、BR,若AR叉乘BR为负数，则A点为bl,B点为br，反之同理。

四、**卡尔曼滤波（class kalman）**
用匀速直线运动模型 先滤出矫正后的点 再通过保存上一帧得到的数据预测出下一帧的坐标点 装甲板的预测为分别预测xy坐标，神符的预测则为预测装甲板中心点与中心r标中心点连线相对于水平线的角度，再解算出坐标。

五、**重力补偿（class compensator）**
通过抛物线模型，利用求根公式直接解算出补偿角度。分为两种情况：
①装甲板在枪管上：（详见代码内函数）
此种情况取负根
②装甲板在枪管下：（详见代码内函数）
此种情况取正根
如何判断两种情况：通过set函数。set函数内容为通过装甲板在图像坐标系的点和窗口中心点做比较

六、**信息匹配（class target）**
本套代码中专门定义了target类来做图像绘制，计算距离和偏转角度。
获取目标装甲板与中心二点之间的角度偏转极坐标以及相机与装甲板击打点的距离。

---
## 二 、Armor Detect

### 1.功能介绍
|模块     |功能     |
| ------- | ------ |
|装甲板识别| 检测敌方机器人装甲板位置信息 |
|位置预测| 自瞄时检测移动靶 |
|角度解算| 根据上述位置信息解算目标相对枪管的yaw、pitch角度及距离 |
|相机驱动| 实现相机参数控制及图像采集 |
---
### 2.效果展示
#### 装甲板识别
装甲板识别采用基于OpenCV的传统算法实现装甲板位置检测。因为读取的是彩色图，直方图均衡化需要在HSV空间做,同时开操作 (去除一些噪点)，闭操作 (连接一些连通域)。
识别得到装甲板在图像中四个顶点、中心点的坐标信息。 

#### 位置预测（class kalman）
用匀速直线运动模型 先滤出矫正后的点 再通过保存上一帧得到的数据预测出下一帧的坐标点 装甲板的预测为分别预测xy坐标，神符的预测则为预测装甲板中心点与中心r标中心点连线相对于水平线的角度，再解算出坐标。

#### 角度解算  
角度解算方面使用了P4P算法。 

---
### 3.实现方案  
#### 装甲板识别  
装甲板识别使用基于检测目标特征的OpenCV传统方法，实现检测识别的中心思想是找出图像中所有敌方颜色灯条，并使用找出的灯条一一拟合并筛选装甲板。 
主要步骤分为：**图像预处理**、**灯条检测**、**装甲板匹配**、**装甲板数字识别**及最终的**目标装甲板选择**。 
1. **图像预处理** 
为检测灯条，需要进行颜色提取。颜色提取基本思路有BGR、HSV、通道相减法。 
因为读取的是彩色图，直方图均衡化需要在HSV空间做,同时开操作 (去除一些噪点)，闭操作 (连接一些连通域)。

2. **灯条检测** 
灯条检测主要是先对预处理后的二值图找轮廓（findContours），
使用得到的旋转矩形（RotatedRect）构造灯条。

3. **装甲板匹配** 
分析装甲板特征可知，装甲板由两个长度相等互相平行的侧面灯条构成。
我们对检测到的灯条进行两两匹配，解算出中心点，得到灯条在相机面四个角点的坐标（ImagePoints），同时以枪管中心为原点、装甲板长宽构造世界坐标系（ObjectPoints），方便代入PNP解算。

---

#### 角度解算  
角度解算部分使用了两种模型解算枪管直指向目标装甲板所需旋转的yaw和pitch角。 

---
## 三、兑换站识别
### 1.功能介绍
本套代码用于兑换站角点检测识别
---
### 2.整体框架
本套代码分为三大部分
第一部分：图像处理（class init）
第二部分：角点轮廓识别(class Exchange）
第三部分：第一次标定（class ArmorBox）
第四部分：第二次标定（class sort）
---
### 3.实现方案  
一、**图像处理（class init）**
通过颜色通道相减得到灰度图，再进行腐蚀膨胀的操作

二、**角点轮廓识别(class Exchange）**
通过面积和旋转矩形长宽比筛选得到目标四个轮廓

三、**第一次标定（class ArmorBox）**
①将四个点的x，y坐标值之和相加得到数组，通过求自定义函数求最大值与最小值的元素在速度中的位置极为该点在vector point里面的位置。相加值最小的为左上点tl，
相加值最大的为右下点br。
②分别求出剩下两个点A,B和左上点的向量，并进行A与B叉乘，若得到的结果为负则A点为右上，B点为左下，若结果为正则相反。
将角点轮廓中心点标定结果拟合成一个大矩形，并算出中心点。

四、**第二次标定（class sort）**
接下来将图像识别步骤中识别到角点的四个轮廓便利并计算与上一步得到的中心点的距离，找出距离最大的这个点为新的角点，从此获得四个角点，并按照上面同样的方法进行标定，传入solvepnp解算。


---
## 四、神经网络
### 1.功能介绍
利用ONNX-runtime在C++上进行部署，并加载测试图片进行分类。
---
### 2.整体框架
首先对图像进行分类，分成训练集和测试集，呃，本套代码使用的是3:1。且相同目录下的红蓝装甲板图片相同。先对图像进行大小的裁剪，使得所有图像的大小相同。再传入自定义网络。经历两层卷积和两层池化，再输入全连接层，得到6个结果。并把结果通过save函数生成为pth。再通过另一个程序将pth转化为onnx模型。

在c++部署：首先下载onnx包，然后导入onnx模型，并通过bin函数对载入测试的图片进行处理，得到预测矩阵后输出最大值的坐标位置，即为预测结果


---
## 五、ROS
(1)在基于装甲板检测函数的基础上，将原先程序包变为ros程序包，改CMakeLists.txt和package.xml
(2)修改ArmorDetect.cpp和ArmorDetect.hpp添加构造函数，传递ros句柄，添加发布者发布图像。
(3)在main函数中构造发布者，发布rviz的图形话题
(4)平移矩阵的拟合较好但不足之处在于仿真旋转矩阵的变量时会有抖动


---
## 六、总结

天天在实验室和大家一起学习的日子真的很开心，师兄们都很和蔼，很愿意教我们，很感谢大家！


git仓库地址：

https://github.com/LvLv79/Task20221007.git

